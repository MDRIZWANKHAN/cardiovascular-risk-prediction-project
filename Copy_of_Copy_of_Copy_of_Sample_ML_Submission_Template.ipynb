{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "FJNUwmbgGyua",
        "w6K7xa23Elo4",
        "yQaldy8SH6Dl",
        "mDgbUHAGgjLW",
        "O_i_v8NEhb9l",
        "HhfV-JJviCcP",
        "Y3lxredqlCYt",
        "3RnN4peoiCZX",
        "x71ZqKXriCWQ",
        "7hBIi_osiCS2",
        "JlHwYmJAmNHm",
        "35m5QtbWiB9F",
        "PoPl-ycgm1ru",
        "H0kj-8xxnORC",
        "nA9Y7ga8ng1Z",
        "PBTbrJXOngz2",
        "u3PMJOP6ngxN",
        "dauF4eBmngu3",
        "bKJF3rekwFvQ",
        "MSa1f5Uengrz",
        "GF8Ens_Soomf",
        "0wOQAZs5pc--",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "KSlN3yHqYklG",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "PIIx-8_IphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "g-ATYxFrGrvw",
        "Yfr_Vlr8HBkt",
        "8yEUt7NnHlrM",
        "tEA2Xm5dHt1r",
        "I79__PHVH19G",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "4_0_7-oCpUZd",
        "hwyV_J3ipUZe",
        "3yB-zSqbpUZe",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "bn_IUdTipZyH",
        "49K5P_iCpZyH",
        "Nff-vKELpZyI",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "yLjJCtPM0KBk",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "nqoHp30x9hH9",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "VfCC591jGiD4",
        "OB4l2ZhMeS1U",
        "ArJBuiUVfxKd",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "dJ2tPlVmpsJ0",
        "JWYfwnehpsJ1",
        "-jK_YjpMpsJ2",
        "HAih1iBOpsJ2",
        "zVGeBEFhpsJ2",
        "bmKjuQ-FpsJ3",
        "Fze-IPXLpx6K",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "h_CCil-SKHpo",
        "cBFFvTBNJzUa",
        "HvGl1hHyA_VK",
        "EyNgTHvd2WFk",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO",
        "gCX9965dhzqZ",
        "gIfDvo9L0UH2"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MDRIZWANKHAN/cardiovascular-risk-prediction-project/blob/main/Copy_of_Copy_of_Copy_of_Sample_ML_Submission_Template.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "##### **Name -**             Md Rizwan Khan"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now a days, heart disease prediction has\n",
        "been a major concept in recent world that is\n",
        "impacting the society towards health. The main\n",
        "concept is to identify the age group and heart\n",
        "rate using the Random forest algorithm. Our\n",
        "project tells how the heart rate and condition is\n",
        "estimated based on the inputs such as blood\n",
        "pressure and many more being provided by the\n",
        "user to a system. This is being much better way\n",
        "when it comes with others algorithms the\n",
        "implementation of RFA gives the better\n",
        "experience and provide accurate result. This\n",
        "helps in early prediction of the disease and is\n",
        "used in many ways, where as it is being provided\n",
        "with the input, in order to find the heart rate\n",
        "based on the health condition."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The classification goal is to predict whether the patient has a 10-year risk of future coronary heart disease (CHD)."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -"
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "\n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "\n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "\n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "\n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno #(import for missing value visualization)\n",
        "import scipy.stats as stats\n",
        "from scipy.stats import shapiro\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix,roc_auc_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBRFClassifier"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets load dataset and store into variable as df.\n",
        "df= pd.read_csv('/content/drive/MyDrive/data_cardiovascular_risk.csv')"
      ],
      "metadata": {
        "id": "va6_hVVA16uI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "\n",
        "#To check dataset we can use-:\n",
        "#1. head()- gives rows from upper\n",
        "#2. tail()- gives rows from lower\n",
        "#3. sample()- gives rows randomly(useful for check bias in dataset)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "LY7il3SC2iPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "\n",
        "\n",
        "# To check dataset rows and columns use-:\n",
        "# 1. shape- gives count of rows and column in tuple form (rows,columns)\n",
        "# 2. len()- only give no of rows\n",
        "len(df)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "_9BxCjqx3CgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "\n",
        "# Info function will give high level information about dataset like-:\n",
        "# 1. total no of columns\n",
        "# 2. total no of missing value present in each columns\n",
        "# 3. datatype of data present in each columns\n",
        "# 4. gives memory occupy of dataset in ram"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "NL74H1yG4EnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "\n",
        "# to check duplicate value use duplicated()function.it will give result in boolean.\n",
        "# Use sum() function with duplicated() gives total no of duplicated values.\n",
        "\n",
        "df.duplicated().sum()"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "\n",
        "# To find missing values use isnull().This will give result in boolean,use sum() function to calculate total missing values.\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "\n",
        "# To visualize missing values we have to import missingno library-:\n",
        "\n",
        "msno.bar(df) # This is code to visualize missing values.Here i am using bar graph we can use other graph also like heatmap etc."
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is from an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The classification goal is to predict whether the patient has a 10-year risk of future coronary heart disease (CHD). The dataset provides the patientsâ€™ information. It includes over 3390 records and 17 attributes. Each attribute is a potential risk factor. There are both demographic, behavioral, and medical risk factors."
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "df.columns"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe()"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Demographic:\n",
        "\n",
        "* Sex: male or female(\"M\" or \"F\")\n",
        "* Age: Age of the patient;(Continuous - Although the recorded ages have been truncated to whole numbers, the concept of age is continuous)\n",
        "\n",
        "###Behavioral:\n",
        "\n",
        "* is_smoking: whether or not the patient is a current smoker (\"YES\" or \"NO\")\n",
        "\n",
        "* Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(can be considered continuous as one can have any number of cigarettes, even half a cigarette.)\n",
        "Medical( history):\n",
        "\n",
        "###Medical( history):\n",
        "\n",
        "* BP Meds: whether or not the patient was on blood pressure medication (Nominal)\n",
        "* Prevalent Stroke: whether or not the patient had previously had a stroke (Nominal)\n",
        "* Prevalent Hyp: whether or not the patient was hypertensive (Nominal)\n",
        "* Diabetes: whether or not the patient had diabetes (Nominal)\n",
        "\n",
        "###Medical( current):\n",
        "\n",
        "* Tot Chol: total cholesterol level (Continuous)\n",
        "\n",
        "* Sys BP: systolic blood pressure (Continuous)\n",
        "\n",
        "* Dia BP: diastolic blood pressure (Continuous)\n",
        "\n",
        "* BMI: Body Mass Index (Continuous)\n",
        "\n",
        "* Heart Rate: heart rate (Continuous - In medical research, variables such as heart rate though infact discrete, yet are considered continuous because of large number of possible values.)\n",
        "\n",
        "* Glucose: glucose level (Continuous)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for i in df.columns.tolist():\n",
        "  print(\"No. of unique values in \",i,\"is\",df[i].nunique(),\".\")"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "fFKEr3yZyGXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "# lets drop id column because it just contains unique id number for each patients and will not be useful for prediction.\n",
        "df.drop(['id'],axis=1,inplace=True)\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "ukHZN7MW0cDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I removed Id column from the dataset because there is no significance of ID column for predictig CHD positive."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1-Histogram and KDE plot on age column (Univariate)"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code()\n",
        "# plot histogram on age to see distribution of data:\n",
        "df['age'].plot(kind='hist',bins=20)"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot kde on age to see distribution:\n",
        "df['age'].plot(kind='kde')"
      ],
      "metadata": {
        "id": "KgbE4Rd33wRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['age'].skew()"
      ],
      "metadata": {
        "id": "D7-8NDAr37KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Because for univariate analysis on numerical columns we can plot histogram and kde plot to explore the distribution of data.\n",
        "*  this plot can also help to identify skewness and outliers.\n",
        "* so i used both the plot on age column to get the information about distribution of data."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Age is normally(almost) distributed.\n",
        "* skewness value is near to zero.it means data is almost normally distributed."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "* In our data set we can clearly see that the age group lies between 30 to 72.\n",
        "\n",
        "* we can findout the age group having more risk of TenYearCHD and according to that we can organise some healthcare treatment."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "ROgddEpdSXMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2- Box and Kde Plot on Cigsperday (Univariate)"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "# plot box plot to see outliers:\n",
        "df['cigsPerDay'].plot(kind='box')"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['cigsPerDay'].plot(kind='kde')"
      ],
      "metadata": {
        "id": "nFI6ncPPS_do"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code will give skewness value:\n",
        "df['cigsPerDay'].skew()"
      ],
      "metadata": {
        "id": "hSyntKdKTeey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Some common visualizations for numerical data include histograms, box plots, and density plots.\n",
        "*  These visualizations provide a visual representation of the distribution of the data and can help identify skewness an outliers.\n",
        "* So i used boxplot and kde plot on cigsperday column to explore the distribution of the data."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Cigsperday is not normally distributed.\n",
        "* There are some outliers.\n",
        "* skewness value is 1.22 it means data is positively skewed."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "_QxxahpJV2QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3- Histogram,Kde and Box Plot on totchol Column(Univariate)"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "\n",
        "df['totChol'].plot(kind='hist')"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['totChol'].plot(kind='kde')"
      ],
      "metadata": {
        "id": "1raai6l_WUIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['totChol'].plot(kind='box')"
      ],
      "metadata": {
        "id": "QgM-rtZ9Wa4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['totChol'].skew()"
      ],
      "metadata": {
        "id": "d-yvbBafWfE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Some common visualizations for numerical data include histograms, box plots, and density plots.\n",
        "* These visualizations provide a visual representation of the distribution of the data and can help identify skewness an outliers.\n",
        "* I used kde and histogram to get the information about distribution of data.\n",
        "* I also used box plot to get information about outliers."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* totchol is not normally distributed.\n",
        "* skewness value is 0.94 it means data is positively skewed.\n",
        "* There are ouliers in totchol column."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "eFfu54pTYQY1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4- Bar and Pie Plot on Sex Column (Univariate)"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "# lets see total count of Female and Male in our dataset.\n",
        "df['sex'].value_counts()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot bar chart to check avg. male and female present:\n",
        "df['sex'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "fGWniuIaZi6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see distribution of male and female in percentage:\n",
        "df['sex'].value_counts().plot(kind='pie',autopct='%0.1f%%')"
      ],
      "metadata": {
        "id": "r9U_VDu1ZuYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Some common visualizations for categorical data include count plots and pie charts.\n",
        "* These visualizations provide a visual representation of the distribution of the categories.\n",
        "* I used bar plot to get information about total count of male and female.\n"
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In our dataset number of female is more than the male.\n",
        "* There are 56.7% Female and 43.3% Male."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "sQ7l0tYxjGSA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5- Bar and Pie Plot on is_smoking Column (Univariate)"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "# lets see total no of smoker and non smoker in our dataset by barplot:\n",
        "df['is_smoking'].value_counts().plot(kind='bar')"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_smoking'].value_counts().plot(kind='pie',autopct='%0.1f%%')"
      ],
      "metadata": {
        "id": "J5jbIt7OkUUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Some common visualizations for categorical data include bar plots and pie charts.\n",
        "* These visualizations provide a visual representation of the distribution of the categories.\n",
        "* I used bar plot to get information about average number of male and female.\n",
        "* I also used pie chart which helped me to get the percentage comparision between Male and Female."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* In our dataset it has been observed that both smoker and non smoker are present in equal number.\n"
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "cGHyYeSBwDRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6- Kde Plot between TenYearCHD Positive VS Age and TenYearCHD Negative VS Age (Bivariate)"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "# lets see kde plot on age having TenYearCHD Positive:\n",
        "df[df['TenYearCHD']==1]['age'].plot(kind='kde',label='CHD Positive')\n",
        "# plot kde on age having TenYearCHD Negative:\n",
        "df[df['TenYearCHD']==0]['age'].plot(kind='kde',label='CHD Negative')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*  Because kdeplot compare the distribution of the numerical data across different categories of the categorical data.\n",
        "* Here i used kdeplot to compare the probability of CHD Positive and CHD Negative with different age group."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights which i found from this plot-:\n",
        " * Chances of getting CHD Positive under 30 years are very less.\n",
        " * We can clearly observed that at the age of 30 to 50 CHD Negative plot is above than CHD Positive plot,it means that there are less chances of getting CHD Positive under these age.\n",
        " * After 50 years to 75 years, CHD Positive plot is above than CHD Negative plot,it means that chances of getting CHD Positive under these age are more."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* yes gained insights helps to many organisations to create a positive business growth:\n",
        "* In healthcare departments helathcare provider targeted more on those age groups which are having more chances of getting CHD positive and run some campaign to provide some healthcare tips,exercises which can reduce the chances of getting CHD positive is less.\n",
        "* Pharmaceutical companies could develop new drugs and treatments that target specific risk factors."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7- Bar Plot Between TenYearCHD VS Sex (Bivariate)\n",
        "#### Chart - 7.1- Bar Plot Between total cigsperday VS Avg CHD Positive Between Male and Female (Multivariate)\n",
        "####"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "# plot countplot with hue parameter gives count of CHD positive and negative indivisually male and female:\n",
        "sns.countplot(x=df['TenYearCHD'],hue=df['sex'])"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# code will give average chances of getting CHD positive corresponding to taking total no of cigsperday\n",
        "df1=df.groupby('cigsPerDay')['TenYearCHD'].mean()*100\n",
        "df1"
      ],
      "metadata": {
        "id": "TjG2VRsy9h6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort the values in desc order:\n",
        "df1=df1.sort_values()\n",
        "df1"
      ],
      "metadata": {
        "id": "gG1WAiC3AZwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert into dataframe:\n",
        "df1=df1.reset_index()\n",
        "df1"
      ],
      "metadata": {
        "id": "4S-gNyRCBX5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "FFCu9yMBY1ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot indivisually male and female corresponding to total cigsperday vs chances of getting CHD positive:\n",
        "plt.figure(figsize=(7,7))\n",
        "sns.barplot(data=df,y='cigsPerDay',x='TenYearCHD',hue='sex',orient='h')\n",
        "plt.xticks(rotation='vertical')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hGnWhwmKBMRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df['sex']=='F')&(df['cigsPerDay']==7.0)].describe()"
      ],
      "metadata": {
        "id": "szGuloVkG7PD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[(df['sex']=='M')&(df['cigsPerDay']==7.0)].describe()"
      ],
      "metadata": {
        "id": "_JYvo-F8I7M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* It has been observed that,some of the males and females are not taking any cigarette instead of that chances of getting CHD positive,it may be happens due to other factors.\n",
        "* In most of the cases, chances of getting CHD positive of males are more whereas cigsperday is same.\n",
        "* In some of the cases chances of getting CHD positive for both males and females are same whereas cigsperday is same.\n",
        "* But actually in our data no of females are more but we are comparing by keeping average cigsperday so indivisually males are taking more cigarette so chances of getting CHD positive should be more in males but some cases it happens in females more,may be some other factors which will impact more for getting CHD positive in females."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Yes some of the organisations can take help to inhance their business by using the gained insights.\n",
        "* Healthcare providers could developing personalized treatment plans that target high risk factors of getting CHD positive.\n",
        "* Fitness companies can target high risk factors and according to that they can make diet plans and include those diets which will not increase high risk factors."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "SMiagTxhSpE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCUVDaqmwi8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8- Kde Plot Between CHD Positive vs totchol and CHD Negative vs totchol (Bivariate)"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "# plot Kde Between CHD Positive vs totchol:\n",
        "df[df['TenYearCHD']==1]['totChol'].plot(kind='kde',label='CHD Positive')\n",
        "# plot Kde Between CHD Negative vs totchol:\n",
        "df[df['TenYearCHD']==0]['totChol'].plot(kind='kde',label='CHD Negative')\n",
        "plt.legend()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Because kdeplot compare the distribution of the numerical data across different categories of the categorical data.\n",
        "\n",
        "* Here i used kdeplot to compare the probability of CHD Positive and CHD Negative with different totchol level."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* It has been observed that totchol level upto 240, CHD negative plot is above the CHD positive plot.\n",
        "* After totchol level 240, CHD positive plot is above the CHD negative plot.\n",
        "* It means that chances of getting CHD positive is more if totchol level more than 240."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Yes the gained insights help to create business impact on many organisatios:\n",
        "* Like we can clearly observed that after totchol level 240 chances of getting CHD positive is more so Pharmaceutical companies could produce some other medicines which will only focus on cholestrol level and reduce the level of cholestrol.\n",
        "* Healthcare providers can run campaign and give some tips and exercises which will focus to reduce cholestrol level."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "JURh_-USU4uK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9- Bar Plot Between TenYearCHD VS Systolic Blood Pressure (Bivariate)"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "sns.barplot(data=df,x='TenYearCHD',y='sysBP')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* It has been observed that the average systolic blood pressure of getting CHD positive is above 140.\n",
        "* There is some difference in both CHD positive and CHD negative height of bar plot,it indicates that systolic blood pressure is important factor which will impact of getting CHD positive."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Yes gained insights help to create positive impact on business:\n",
        "* We can clearly observed from the graph,systolic blood pressure plays a major role for getting CHD positive.\n",
        "* Some of the Pharmaceutical companies could produce some other medicines which will only focus on systolic blood pressure and reduce it,and also manufacture some equipment whose accuracy is more to measure blood pressure.\n",
        "* Healthcare providers provide yoga and exercises to reduce blood pressure."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "_TsLmmLejbMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10- Bar Plot Between TenYearCHD VS BMI (Bivariate)"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "sns.barplot(data=df,x='TenYearCHD',y='BMI')"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* Average BMI for both CHD positive and negative is approx. same.\n",
        "* It has been observed that height difference in both the bar is very less,it means BMI is not that important parameter for getting CHD positive."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After eda the gained insights help in many industries to inhance their businesses:\n",
        "* health and gym centers can target peoples by their BMI level and plans for their workout and diets.\n",
        "* Some of the health industries also produces some product which will help to control BMI levels indivisually."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11- Bar Plot Between TenYearCHD VS glucose (Bivariate)"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization code\n",
        "# Bar plot between glucose and TenYearCHD:\n",
        "sns.barplot(data=df,x='TenYearCHD',y='glucose',palette=['green','red'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* From the bar plot we can conclude that average glucose level for getting CHD positive is somewhere around 88.\n",
        "* It has been observed that there is some difference in height of the bar,it means glucose is important factor for getting CHD positive."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this information healthcare departments identify those peoples who are having high level of glucose and also identify those peoples who are having risk for developing diabetes,heart disease and other health conditions.\n",
        "* Based on this information healthcare providers can take some preventive action to reduce these health issues by implementing such as\n",
        "  * lifestyle changes\n",
        "  * by modification on diet etc"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "-GgWS0h7lkOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12- Bar Plot Between TenYearCHD VS glucose compare with is_smoking (Multivariate)"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "\n",
        "sns.barplot(data=df,x='TenYearCHD',y='glucose',hue='is_smoking',palette=['yellow','green'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* From the plot we can clearly observe that those peoples who are smokers,the average glucose level is reduced from 88 to 81 for getting CHD positive.\n",
        "* But those peoples who are not smokers for those glucose level is high for getting CHD positive.\n",
        "* There is also difference in height of the bar is observed,it means glucose is important factor for getting CHD positive."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "1yCernlEni59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13- Bar Plot Between TenYearCHD VS SysBP Compare with Male and Female (Multivariate)"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "sns.barplot(data=df,x='TenYearCHD',y='sysBP',hue='sex',palette=['pink','maroon'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* Average systolic blood pressure of female is higher than the male for getting CHD positive.\n",
        "* But by this information we cannot say that for getting CHD positive in females average systolic blood pressure should be high because in our data no of females are more than the males,so when calculate average automatically females got higher number."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes the gained insights help to create positive impact on business.\n",
        "\n",
        "* Like Pharmaceutical companies can produces some medicines which will focus to control blood pressure.\n",
        "* Fitness companies can include developing personalized exercise programs to target those peoples who are having high risk of CHD.\n",
        "* Healthcare providers can run campaign and target those peoples who are at high risk of CHD,and also guide to do some exercise which will help to reduce risk of CHD."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "plt.figure(figsize=(11,11))\n",
        "sns.heatmap(df.corr(),annot=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Heatmap--> plot rectangular data as a color encoded matrix.\n",
        "* Heatmap is also give correlations between variables.\n",
        "* I just wanted to know correlations between the variables so that's why i used heatmap."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Insights:\n",
        "\n",
        "* From the above heatmap we can clearly see that there is some positive correlation between TenYearCHD VS Age,TenYearCHD VS sysBP,TenYearCHD VS prevalentHyp,TenYearCHD VS glucose.\n",
        "* There is also some negative correlation between TenYearCHD VS education."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pair Plot visualization code"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Pairplot gives pairwise relationship between numericals column.\n",
        "* Pairplot automatically detect numericals column and then pair by pair draw pairplot between all numerical columns.\n",
        "* I just wanted to see correlation between numericals column for that reason i used pairplot."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1\n",
        "Average Systolic blood pressure(sysBP) of TenYearCHD positive is greater than 140."
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: mu = 140\n",
        "\n",
        "Alternate Hypothesis : mu < 140\n",
        "\n",
        "Test Type: Left Tailed Test\n",
        "\n",
        "mu= Average sysBP of TenYearCHD positive\n",
        "\n"
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# lets extract the sysBP column having TenYearCHD positive and also converted into dataframe:\n",
        "CHD_pos = df[df['TenYearCHD']==1]['sysBP'].reset_index()\n",
        "\n",
        "# lets extract all the values from sysBP column and store it into sample data:\n",
        "sample_data = CHD_pos['sysBP'].values\n",
        "\n",
        "# lets check our data is normal or not:\n",
        "#To check our data is normal or not we perform Shapiro test, after this test we are going to get p value\\\n",
        "# if p value is greater than 0.05 then its considered to be normally distributed.\n",
        "\n",
        "# calculate t_statistic and p value:\n",
        "# ttest_1samp function takes two values and will give t_statistic and p_ value.\n",
        "\n",
        "pop_mean=mu=140\n",
        "t_statistic,p_value =stats.ttest_1samp(sample_data,pop_mean)\n",
        "\n",
        "print('t-statistic:', t_statistic)\n",
        "print('p-value:', p_value/2)\n",
        "\n",
        "# check if the p-value is less than alpha\n",
        "alpha =0.05\n",
        "if p_value < alpha:\n",
        "    print('Reject null hypothesis. Average systolic blood pressure (sysBP) of TenYearCHD positive is greater than 140.')\n",
        "else:\n",
        "    print('Failed to reject null hypothesis. Average systolic blood pressure (sysBP) of TenYearCHD positive is not greater than 140.')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_value = np.mean(sample_data)"
      ],
      "metadata": {
        "id": "WsRDy5jbcAd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "median_value = np.median(sample_data)"
      ],
      "metadata": {
        "id": "Rd-cBT-bcFVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_median_difference=median_value- mean_value\n",
        "print(\"Mean Median Difference is :-\",mean_median_difference)"
      ],
      "metadata": {
        "id": "_S_N0mQrZ-Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2\n",
        "Average glucose of TenYearCHD positive is greater than 88."
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: mu = 85\n",
        "\n",
        "Alternate Hypothesis : mu < 85\n",
        "\n",
        "Test Type: Left Tailed Test\n",
        "\n",
        "mu= Average glucose of TenYearCHD positive\n"
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# lets extract the glucose column having TenYearCHD positive and also converted into dataframe:\n",
        "CHD_pos = df[df['TenYearCHD']==1]['glucose'].reset_index().dropna()\n",
        "\n",
        "# lets extract all the values from sysBP column and store it into sample data:\n",
        "sample_data1 = CHD_pos['glucose'].values\n",
        "\n",
        "# lets check our data is normal or not:\n",
        "#To check our data is normal or not we perform Shapiro test, after this test we are going to get p value\\\n",
        "# if p value is greater than 0.05 then its considered to be normally distributed.\n",
        "\n",
        "# calculate t_statistic and p value:\n",
        "# ttest_1samp function takes two values and will give t_statistic and p_ value.\n",
        "\n",
        "pop_mean=mu=85\n",
        "t_statistic,p_value =stats.ttest_1samp(sample_data1,pop_mean)\n",
        "\n",
        "print('t-statistic:', t_statistic)\n",
        "print('p-value:', p_value/2)\n",
        "\n",
        "# check if the p-value is less than alpha\n",
        "alpha =0.05\n",
        "if p_value < alpha:\n",
        "    print('Reject null hypothesis. Average glucose of TenYearCHD positive is greater than 85.')\n",
        "else:\n",
        "    print('Failed to reject null hypothesis. Average glucose of TenYearCHD positive is not greater than 85.')"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##shapiro_age= shapiro(sample_data1)\n",
        "##print(shapiro_age)"
      ],
      "metadata": {
        "id": "r6Y5TLezVZzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###from scipy.stats import shapiro\n",
        "###shapiro_age= shapiro(sample1)\n",
        "###print(shapiro_age)"
      ],
      "metadata": {
        "id": "CfSZW8706wpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3\n",
        "Average totchol of TenYearCHD positive is greater than 242."
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis: mu = 242\n",
        "\n",
        "Alternate Hypothesis : mu < 242\n",
        "\n",
        "Test Type: Left Tailed Test\n",
        "\n",
        "mu= Average totchol of TenYearCHD positive"
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "JPG7L6HymlvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "# lets extract the glucose column having TenYearCHD positive and also converted into dataframe:\n",
        "CHD_pos = df[df['TenYearCHD']==1]['totChol'].reset_index().dropna()\n",
        "\n",
        "# lets extract all the values from sysBP column and store it into sample data:\n",
        "sample_data1 = CHD_pos['totChol'].values\n",
        "\n",
        "# lets check our data is normal or not:\n",
        "#To check our data is normal or not we perform Shapiro test, after this test we are going to get p value\\\n",
        "# if p value is greater than 0.05 then its considered to be normally distributed.\n",
        "\n",
        "# calculate t_statistic and p value:\n",
        "# ttest_1samp function takes two values and will give t_statistic and p_ value.\n",
        "\n",
        "pop_mean=mu=242\n",
        "t_statistic,p_value =stats.ttest_1samp(sample_data1,pop_mean)\n",
        "\n",
        "print('t-statistic:', t_statistic)\n",
        "print('p-value:', p_value/2)\n",
        "\n",
        "# check if the p-value is less than alpha\n",
        "alpha =0.05\n",
        "if p_value < alpha:\n",
        "    print('Reject null hypothesis. Average totchol of TenYearCHD positive is greater than 242.')\n",
        "else:\n",
        "    print('Failed to reject null hypothesis. Average totchol of TenYearCHD positive is not greater than 85.')"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to fill null values of categorical columns with mode.\n",
        "def mode_fillna(df1,columns):\n",
        "  for column in columns:\n",
        "    df[column]=df[column].fillna(df[column].mode()[0])"
      ],
      "metadata": {
        "id": "RjQDRsDL9PQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the function to fill null values on categorical columns with mode.\n",
        "mode_fillna(df1=df,columns=['education','BPMeds'])"
      ],
      "metadata": {
        "id": "bxvsw60E-fa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "ljsnQHMX_SPt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a function to fill null values of numerical columns with median.\n",
        "def median_fillna (df2,columns):\n",
        "  for column in columns:\n",
        "    df2[column]=df2[column].fillna(df2[column].median())"
      ],
      "metadata": {
        "id": "iFRbEzJm_enk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Applying the function to fill null values on numerical columns with median.\n",
        "median_fillna(df2=df,columns=['cigsPerDay','totChol','BMI','heartRate','glucose'])"
      ],
      "metadata": {
        "id": "akhXJClGAh-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Ugn2Ib6jBVwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Missing value imputation techniques:\n",
        "\n",
        "1. I used to fill missing values in categorical columns like education and BPMeds by mode.\n",
        "\n",
        "  #### Why did i used-:\n",
        "   * We generally fill missing values with the mode in scenarios where the data is categorical or nominal.\n",
        "   * mode represents the most common value in the dataset and is often used as a measure of central tendency.\n",
        "\n",
        "2. I used to fill missing values in numerical columns by median.\n",
        "\n",
        "   #### Why did i used-:\n",
        "   * we fill missing values with the median when the data has a skewed distribution.\n",
        "   * In a skewed distribution, the mean may not accurately represent the central tendency of the data, and extreme values can greatly influence the mean.\n",
        "   *  In such cases, using the median as a measure of central tendency can be more appropriate because it is less sensitive to outliers.\n",
        "   * So thats why here i used median to fill missing values because data is skewed.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "df_num=df.select_dtypes(['int64','float64'])\n",
        "df_num\n"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in df_num.columns:\n",
        "\n",
        "  plt.figure(figsize=(9,5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  fig = sns.boxplot(y=df_num[var])\n",
        "  fig.set_title('')\n",
        "  fig.set_ylabel(var)\n",
        "\n",
        " # plt.subplot(1, 2, 2)\n",
        "  #fig = sns.distplot(df_num[var].dropna())\n",
        "  #fig.set_ylabel('Number of houses')\n",
        "  #fig.set_xlabel(var)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mgVucAaNE4UR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for var in df_num.columns:\n",
        "\n",
        "  plt.figure(figsize=(9,5))\n",
        "  plt.subplot(1, 2, 1)\n",
        "  fig=sns.boxplot(np.log10(df_num[var]))\n",
        "  fig = sns.boxplot(y=df_num[var])\n",
        "  fig.set_title('')\n",
        "  fig.set_ylabel(var)\n",
        "\n",
        " # plt.subplot(1, 2, 2)\n",
        "  #fig = sns.distplot(df_num[var].dropna())\n",
        "  #fig.set_ylabel('Number of houses')\n",
        "  #fig.set_xlabel(var)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "R_rSmCSNCMw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Actually according to our dataset in some of the columns the difference of the values are very high.\n",
        "* So we cannot treat those values as outliers because those values can help me to predict TenYearCHD Positive.\n",
        "* So according to me those values are not outliers,so there is no need to treat them."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "df.head(2)"
      ],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a label encoder based on above data\n",
        "encoder = {'sex':{'M':1, 'F':0},'is_smoking':{'YES':1, 'NO': 0}}\n",
        "\n",
        "# Label Encoding\n",
        "df = df.replace(encoder)"
      ],
      "metadata": {
        "id": "fIThFGIZiFhX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "LdaaB_feiIH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Actually i used dictionary-based approach to replace categorical values with numerical values in a pandas DataFrame using the replace()\n",
        "method.\n",
        "* I used this technique because this is simple to use and these are binary categorical columns."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "y0_kk-bri--6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "\n",
        "# lets drop is_smoking column because same information we can get from cigsperday as it contains some values and zero means someone\n",
        "df.drop('is_smoking',axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lets create new column averageBP because for CHD positive both systolic(high value) and distolic(high value) is dangerous.\n",
        "df[\"differenceinBP\"] = ((df[\"sysBP\"] - df[\"diaBP\"]))\n",
        "\n",
        "# Drop the original sysBP and diaBP columns\n",
        "df.drop([\"sysBP\", \"diaBP\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "0wykrcGZkYjf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "McTgstkUrOdw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=df.iloc[:,12:13]\n",
        "y"
      ],
      "metadata": {
        "id": "VDZaXjabX_tM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "mXEw1x9vueVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting\n",
        "\n",
        "def cal_vif (dataset):\n",
        "  vif = pd.DataFrame()\n",
        "  vif['features']=dataset.columns\n",
        "  vif['VIF_value']=[variance_inflation_factor(dataset.values,i) for i in range(dataset.shape[1])]\n",
        "  return(vif)"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_vif(df)"
      ],
      "metadata": {
        "id": "u6Geftygwg2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['education','TenYearCHD'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "sNvnYO93yrQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_vif(df)"
      ],
      "metadata": {
        "id": "-Yqv5eK5y2g2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(2)"
      ],
      "metadata": {
        "id": "06ulBCQK2fUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I used Variance Inflation Factor (VIF).\n",
        "* VIF measure multicollinearity of independent variable.\n",
        "* VIF values greater than 1 indicate that there is some degree of multicollinearity between independent variables.\n",
        "*  VIF value greater than 5 or 10 is considered to be high levels of multicollinearity, and variables with high VIF values may need to be removed from the model to improve its accuracy.\n",
        "\n",
        "   #### why did i use this-:\n",
        "   * because VIF method is used to identify independent variables that are highly correlated with each other and may be redundant in the model.\n",
        "   * By removing these variables, we can improve the accuracy."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform Your data\n",
        "def skewness(df,variable):\n",
        "  for i in variable:\n",
        "    s=df[i].skew()\n",
        "    print(f'Skewness value of {i} is: {s}')\n"
      ],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skewness(df,df.columns)"
      ],
      "metadata": {
        "id": "5wWzzC19Cq1e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnostic_plot(df,variable):\n",
        "  plt.figure(figsize=(12,6))\n",
        "  plt.subplot(1,2,1)\n",
        "  df[variable].hist()\n",
        "\n",
        "  plt.subplot(1,2,2)\n",
        "  stats.probplot(df[variable],dist='norm',plot=plt)\n",
        "\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "ceNDfT9aIWpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic_plot(df,'glucose')"
      ],
      "metadata": {
        "id": "Qt_MU4_sJcF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['glucose']=np.log1p(df['glucose']).values\n",
        "diagnostic_plot(df,'glucose')"
      ],
      "metadata": {
        "id": "ugqMzZEpKnrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['glucose'].skew()"
      ],
      "metadata": {
        "id": "IPav7OWKK-JY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(1)"
      ],
      "metadata": {
        "id": "pc39GAiBnEJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diagnostic_plot(df,'differenceinBP')"
      ],
      "metadata": {
        "id": "hU_QQArBM7Uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['differenceinBP']=np.log1p(df['differenceinBP']).values\n",
        "diagnostic_plot(df,'differenceinBP')"
      ],
      "metadata": {
        "id": "Je83xXWcNHFN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['differenceinBP'].skew()"
      ],
      "metadata": {
        "id": "Z40AZt8iNaQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Yes data transformation is required in our dataset.\n",
        "* Because when we calculate skewness values of each columns then i found some of the columns their skewness value is very far away from zero.\n",
        "* If skewness value is close to zero then it is considered to be normal distribution.\n",
        "\n",
        " I used log transformation to transform data because in some of the columns our data is positively skewed and for positively skewed lof transformation is used."
      ],
      "metadata": {
        "id": "A1KusARRiGwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "scaler=MinMaxScaler()\n",
        "X=scaler.fit_transform(df)\n",
        "X\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I used MinMaxScaler.\n",
        "* MinMaxScaler is a popular feature scaling technique used to transform numerical features to a common scale. It scales the features to a fixed range (usually between 0 and 1) based on the minimum and maximum values of the features.\n",
        "\n",
        "   #### Why MinMaxScaler Used -:\n",
        "   * Shape of the distribution is not changed when used MinMaxScaler.\n",
        "   * This can be useful when the distribution of the original data is important for the analysis.\n",
        "   * MinMaxScaler is robust to outliers.\n",
        "   * MinMaxScaler is also simple to use."
      ],
      "metadata": {
        "id": "oiKJtj8PkocZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        " # split into 80:20 ratio\n",
        "X_train,X_test,y_train,y_test = train_test_split( X,y , test_size = 0.2, random_state =1)"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used 80:20 data splitting ratio because there are some benefits:\n",
        "\n",
        "* #### Reduced bias: #####\n",
        "By splitting our data into different sets, we can reduce the bias that might happens when our model train and test on same data.\n",
        "\n",
        "  *  This will help us to avoid overfitting.\n",
        "\n",
        "* #### Increased robustness:\n",
        "\n",
        "  *  When we split our data into training and test sets, we're essentially creating two different datasets that we can use to test our model's performance. This can help us identify any issues with our data, such as outliers or missing values, and make our model more robust to these issues."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "id": "QnQpAN-ZWr61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y.TenYearCHD.value_counts()"
      ],
      "metadata": {
        "id": "17elAff-tXw_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)\n",
        "# Handaling imbalance dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train.value_counts()"
      ],
      "metadata": {
        "id": "9JmM6Un9l7pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used SMOTE (Synthetic Minority Over-sampling technique) for balanced the   dataset.\n",
        "\n",
        "SMOTE is a technique in machine learning for dealing with issues that arise when working with an unbalanced data set. In practice, unbalanced data sets are common and most ML algorithms are highly prone to unbalanced data so we need to improve their performance by using techniques like SMOTE.\n",
        "\n",
        "SMOTE has the advantage of not creating duplicate data points, but rather synthetic data points that differ slightly from the original data points. SMOTE is a superior oversampling option.\n",
        "\n",
        "That's why for lots of advantages, I have used SMOTE technique for balancinmg the dataset."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1- **Implementing Logistic Regression**"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation\n",
        "clf = LogisticRegression(fit_intercept=True, max_iter=10000)\n",
        "\n",
        "# Fit the Algorithm\n",
        "clf.fit(X_train,np.ravel(y_train,order='C'))\n",
        "# Predict on the model\n",
        "y_pred_train=clf.predict(X_train)\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# get accuracy score on train data:\n",
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "# get accuracy score on test data:\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n",
        "\n"
      ],
      "metadata": {
        "id": "rqD5ZohzfxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the confusion matrix for test data:\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "t4s7FrZ0eSyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lets draw heatmap for confusion matrix\n",
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "NX96S9T8o3Uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "vV5TlGmAqavo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc"
      ],
      "metadata": {
        "id": "9PjyHygqBYJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_auc"
      ],
      "metadata": {
        "id": "aX4ujO68Bacg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "S5tn0IH2r4zF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nza411qusdnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I used Logistic regression algorithm to create the model. As I got not so good result.\n",
        "\n",
        "For testing dataset, i found precision of 93% and recall of 64% and f1-score of 76% for TenYearCHD negative.And I got precision of 24% and recall of 69% and f1-score of 36% for TenYearCHD Positive,and Accuracy is 65%.\n",
        "\n",
        "Now,tryting to improving the score by using hyperparameter tuning technique.\n",
        "\n"
      ],
      "metadata": {
        "id": "NI3g0eJ5k9IL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "param_grid = {'C': [10,1,0.1,0.01],\n",
        "              'solver':['lbfgs','liblinear','saga']}\n",
        "\n",
        "# Initializing the logistic regression model\n",
        "clf = LogisticRegression(fit_intercept=True, max_iter=10000, random_state=0)\n",
        "# Using GridSearchCV to tune the hyperparameters using cross-validation\n",
        "grid = GridSearchCV(clf, param_grid, cv=5)\n",
        "grid.fit(X_train, np.ravel(y_train,order='C'))\n",
        "\n",
        "best_params = grid.best_params_\n",
        "# The best hyperparameters found by GridSearchCV\n",
        "print(\"Best hyperparameters: \", best_params)"
      ],
      "metadata": {
        "id": "DCYVavEenhb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)"
      ],
      "metadata": {
        "id": "yCSJ0z9WQx8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the confusion matrix for test data:\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "ft6g5KD2qxOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uv88YOPeq2bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "6cnjObzRq8J2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc"
      ],
      "metadata": {
        "id": "tspFHUgDq__M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_auc"
      ],
      "metadata": {
        "id": "ETNVTwvcrBDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "x3TxFIogrI9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jxAC3jlGrNvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique used is GridSearchCV. GridSearchCV is a method that performs an exhaustive search over a specified parameter grid to find the best hyperparameters for a model. It is a popular method for hyperparameter tuning because it is simple to implement and can be effective in finding good hyperparameters for a model.\n",
        "\n",
        "The choice of hyperparameter optimization technique depends on various factors such as the size of the parameter space, the computational resources available, and the time constraints. GridSearchCV can be a good choice when the parameter space is relatively small and computational resources are not a major concern."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that hyperparameter tuning did not improve the performance of the Logistic Regression model on the test set."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "clf= RandomForestClassifier(max_depth=9, random_state=0)\n",
        "\n",
        "# Fit the Algorithm\n",
        "clf.fit(X_train,np.ravel(y_train,order='C'))\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_train=clf.predict(X_train)\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "8_MXhqijDCRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the confusion matrix for test data:\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "metadata": {
        "id": "LSEf-XCyr89E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DiCFqHUusDyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "HjOqhtSVsIuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "NQSEFHeAsNL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wgFxh_iYsXJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JyYC4gorsbWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "clff= RandomForestClassifier(random_state=0)\n",
        "param = {'n_estimators' : [50, 65, 80, 95],\n",
        "        'max_depth' : [3,5,7,9,11]}\n",
        "grid = GridSearchCV(clff, param_grid = param, cv=5,scoring = 'roc_auc')\n",
        "# Fit the Algorithm\n",
        "grid.fit(X_train,np.ravel(y_train,order='C'))\n",
        "\n",
        "\n",
        "grid.best_params_\n"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict on the model\n",
        "y_pred_train=grid.predict(X_train)\n",
        "y_pred=grid.predict(X_test)"
      ],
      "metadata": {
        "id": "goXiSemQD9d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n"
      ],
      "metadata": {
        "id": "cUDVzHRyJ6x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)"
      ],
      "metadata": {
        "id": "d9Ct-vChIiaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "01AKjNKptzgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "YYiJgW1Tt-FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "zEx87gKdt_ZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "H74pCeFJuOgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0p5I9ikPuSeh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique used is GridSearchCV. GridSearchCV is a method that performs an exhaustive search over a specified parameter grid to find the best hyperparameters for a model. It is a popular method for hyperparameter tuning because it is simple to implement and can be effective in finding good hyperparameters for a model.\n",
        "\n",
        "The choice of hyperparameter optimization technique depends on various factors such as the size of the parameter space, the computational resources available, and the time constraints. GridSearchCV can be a good choice when the parameter space is relatively small and computational resources are not a major concern."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training dataset, i found precision of 98% and recall of 94% and f1-score of 96% for TenYearCHD Negative.And I got precision of 94% and recall of 98% and f1-score of 96% for TenYearCHD Positive. Accuracy is 96%.\n",
        "\n",
        "For testing dataset, i found precision of 89% and recall of 82% and f1-score of 86% for TenYearCHD Negative.And I got precision of 28% and recall of 41% and f1-score of 33% TenYearCHD Positive. Accuracy is 77%.\n",
        "\n",
        "It appears that hyperparameter tuning improved the performance of the Random Forest model on the test set. The tuned Random Forest model has higher precision, recall, accuracy, and F1 score on the test set compared to the untuned Random Forest model. The ROC-AUC score on the test set also improved slightly after tuning."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "clf = KNeighborsClassifier()\n",
        "\n",
        "# Fit the Algorithm\n",
        "clf.fit(X_train,np.ravel(y_train,order='C'))\n",
        "# Predict on the model\n",
        "y_pred_train=clf.predict(X_train)\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SnnFj9PCPoAC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "M-pZMUIbP9YP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "zQ_FT8KrP_Yj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ENaVzlRsQKF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YGc2ypkoQPYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "grid = {'n_neighbors' : [9,11],\n",
        "        'metric' : ['minkowski','euclidean','manhattan']}\n",
        "knn = GridSearchCV(clf, param_grid = grid, n_jobs=-1, cv=9)\n",
        "# Fit the Algorithm\n",
        "knn.fit(X_train,np.ravel(y_train,order='C'))\n",
        "# Predict on the model\n",
        "#y_pred_train=clf.predict(X_train)\n",
        "#y_pred=clf.predict(X_test)\n",
        "\n",
        "knn.best_params_"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_train=clf.predict(X_train)\n",
        "y_pred=clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "LNqkXAv8vEXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)"
      ],
      "metadata": {
        "id": "YSgTT_FuWaH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-luD2yskQaqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "4qtrSANDQm8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "l-_RczXaQoI0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jnDOMwYlQ3ml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "okxHbDjsQ8k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "b66MD74JQfU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "our goal should be to find the best hyperparameters values to get the perfect prediction results from our model. But the question arises, how to find these best sets of hyperparameters? One can try the Manual Search method, by using the hit and trial process and can find the best hyperparameters which would take huge time to build a single model.\n",
        "\n",
        "For this reason, methods like Random Search, GridSearch were introduced. Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved.\n",
        "\n",
        "In GridSearchCV, along with Grid Search, cross-validation is also performed. Cross-Validation is used while training the model.\n",
        "\n",
        "That's why I have used GridsearCV method for hyperparameter optimization."
      ],
      "metadata": {
        "id": "WmjZTPkpQkgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "XMcw4jmhQ16z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It appears that hyperparameter tuning did not improve the performance of the KNN model on the test set."
      ],
      "metadata": {
        "id": "hBiRnASvQ_CV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model-4"
      ],
      "metadata": {
        "id": "YRp4LLz1xBaJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "clf = SVC(random_state= 0,probability=True)\n",
        "\n",
        "# Fit the Algorithm\n",
        "clf.fit(X_train,np.ravel(y_train,order='C'))\n",
        "# Predict on the model\n",
        "y_pred_train=clf.predict(X_train)\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "ItkoWCbuxRx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "gMNEtpYryb-I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "rPUfzCHJyiOu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mdijk2ESx6cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "N1mnPKXzx_aE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "_HSwdNdZyFpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7bK1o2UQyT7z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "djxLIIA4yXz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "BWLXc2nlzFRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the SVC classifier\n",
        "clf = SVC(random_state=0, probability=True)\n",
        "\n",
        "# Define the parameter grid for hyperparameter tuning\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Perform GridSearchCV for cross-validation and hyperparameter tuning\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(X_train, np.ravel(y_train, order='C'))\n",
        "\n",
        "# Get the best parameters and best score from the grid search\n",
        "best_params = grid_search.best_params_\n",
        "best_score = grid_search.best_score_\n",
        "\n",
        "# Create a new SVC instance with the best parameters\n",
        "best_clf = SVC(random_state=0, **best_params)\n",
        "best_clf.fit(X_train, np.ravel(y_train, order='C'))\n",
        "\n",
        "# Predict on the training set\n",
        "y_pred_train = best_clf.predict(X_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred_test = best_clf.predict(X_test)\n"
      ],
      "metadata": {
        "id": "oke4cny5VyZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred_test)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "iy8pAiWB0CD1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8GxIqYrTyeFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "AlvumXPzymoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "0ChHKZiHyoHl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Sl7tRlQsyv2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DBPFNAtjy0KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "3sya50yXSUjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearchCV which uses the Grid Search technique for finding the optimal hyperparameters to increase the model performance.\n",
        "\n",
        "our goal should be to find the best hyperparameters values to get the perfect prediction results from our model. But the question arises, how to find these best sets of hyperparameters? One can try the Manual Search method, by using the hit and trial process and can find the best hyperparameters which would take huge time to build a single model.\n",
        "\n",
        "For this reason, methods like Random Search, GridSearch were introduced. Grid Search uses a different combination of all the specified hyperparameters and their values and calculates the performance for each combination and selects the best value for the hyperparameters. This makes the processing time-consuming and expensive based on the number of hyperparameters involved.\n",
        "\n",
        "In GridSearchCV, along with Grid Search, cross-validation is also performed. Cross-Validation is used while training the model.\n",
        "\n",
        "That's why I have used GridsearCV method for hyperparameter optimization."
      ],
      "metadata": {
        "id": "_BCB6NrpSciW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "njLIhMbMSi2x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* It appears that hyperparameter tuning improved the performance of the SVM model on dataset.\n",
        "* The tuned SVM model has higher recall, accuracy, and F1 score on the test set compared to the untuned SVM model.\n",
        "* But the accuracy of train and test is equal it may be due to possible that the chosen algorithm (SVC in this case) may not be the best fit for your specific dataset,so will try different algorithem on this."
      ],
      "metadata": {
        "id": "uohFjt9VSqaD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model-5"
      ],
      "metadata": {
        "id": "UeVfDb5h1StY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 4 Implementation\n",
        "clf = XGBRFClassifier(random_state=3)\n",
        "# Fit the Algorithm\n",
        "clf.fit(X_train,np.ravel(y_train,order='C'))\n",
        "# Predict on the model\n",
        "y_pred_train=clf.predict(X_train)\n",
        "y_pred=clf.predict(X_test)"
      ],
      "metadata": {
        "id": "XW1j0iq71aN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "VijQmwRl2X26"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "9oEgptCb2dcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5VgOkYwBy2zO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "AZi9APKMy_Mu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "5qfmS9cEzAkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n4hd6FK4zJ3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bUbFgNnuzNg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "KvzJvbmm2yLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "param = {'n_estimators' : [120,130,140],\n",
        "        'max_depth' : [13,15,17],\n",
        "        'eta' : [0.001,0.01,0.05,0.08]}\n",
        "grid = GridSearchCV(clf, param_grid = param, cv=5)\n",
        "# Fit the Algorithm\n",
        "grid.fit(X_train,np.ravel(y_train,order='C'))\n",
        "# Predict on the model\n",
        "y_pred_train=grid.predict(X_train)\n",
        "y_pred=grid.predict(X_test)"
      ],
      "metadata": {
        "id": "B_EkCJLOKzJb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "id": "zqQkreiSMeF5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = accuracy_score(y_train,y_pred_train)\n",
        "test_accuracy = accuracy_score(y_test,y_pred)\n",
        "\n",
        "print(\"The accuracy on train data is \", train_accuracy)\n",
        "print(\"The accuracy on test data is \", test_accuracy)\n"
      ],
      "metadata": {
        "id": "lJ-3wcuJ3PfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "sns.heatmap(cm, annot=True, ax = ax) #annot=True to annotate cells\n",
        "\n",
        "# labels, title and ticks\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1tlS2dWFzSTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the roc_auc score for train and test dataset\n",
        "train_auc = roc_auc_score(y_train,y_pred_train)\n",
        "test_auc = roc_auc_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "7V7ZUbNvzeVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_auc,test_auc"
      ],
      "metadata": {
        "id": "mLd5hBITzfx0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on train data\n",
        "report_data = classification_report(y_train, y_pred_train, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VXw1mIDPzk-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the classification report using a heatmap on test data\n",
        "report_data = classification_report(y_test,y_pred, output_dict=True)\n",
        "report_df = pd.DataFrame(report_data).transpose()\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(report_df.iloc[:-1, :].T, annot=True, cmap=\"Blues\")\n",
        "plt.xlabel('Metrics')\n",
        "plt.ylabel('Classes')\n",
        "plt.title('Classification Report')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "UhhOP9BHzqzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameter optimization technique used is GridSearchCV. GridSearchCV is a method that performs an exhaustive search over a specified parameter grid to find the best hyperparameters for a model. It is a popular method for hyperparameter tuning because it is simple to implement and can be effective in finding good hyperparameters for a model.\n",
        "\n",
        "The choice of hyperparameter optimization technique depends on various factors such as the size of the parameter space, the computational resources available, and the time constraints. GridSearchCV can be a good choice when the parameter space is relatively small and computational resources are not a major concern."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Yes,By using XGBOOST accuracy increases on both train and test dataset.\n",
        "\n",
        "#### For untuned XGBOOST-:\n",
        "\n",
        "  * For training dataset, i found accuracy 78% and for test dataset 72%.\n",
        "\n",
        "#### For tuned XGBOOST-:\n",
        " * For training dataset i found acccuracy 99% and for test dataset 79%.\n",
        " * recall= 33%%\n",
        " * precision = 29%\n",
        " * Accuracy(Test) = 79%\n",
        "For testing dataset, i found precision of 89% and recall of 82% and f1-score of 86% for TenYearCHD Negative.And I got precision of 28% and recall of 41% and f1-score of 33% TenYearCHD Positive. Accuracy is 77%.\n",
        "\n",
        "It appears that hyperparameter tuning improved the performance of the Random Forest model on the test set. The tuned Random Forest model has higher precision, recall, accuracy, and F1 score on the test set compared to the untuned Random Forest model. The ROC-AUC score on the test set also improved slightly after tuning."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data."
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the conclusion here."
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}